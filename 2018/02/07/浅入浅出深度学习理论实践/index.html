<!DOCTYPE html>



  

<html class="theme-next muse use-motion" lang="zh-Hans">


<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="理论解析," />










<meta name="keywords" content="理论解析">
<meta property="og:type" content="article">
<meta property="og:title" content="浅入浅出深度学习理论实践">
<meta property="og:url" content="http://sladesha.github.io/2018/02/07/浅入浅出深度学习理论实践/index.html">
<meta property="og:site_name" content="SladeSha&#39;s Algorithm World">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-c6cc20032d7d0314.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-772dffb29dc4d9c0.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-47d1b5a6fb64a4f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-071901b190573269.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-d2bd2d98ce6fd07d.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-0ed7c1c4734f9206.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-a79b2232f850395b.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-1ce76cadc5718922.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-a1a5d8e2b907771f.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-56235bdd16fba64e.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-a186f2410acb046d.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-1277229fc560f408.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-33c3f5aa3d6445a7.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-246995854fe4a3f1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-0fb4f9504f5a996a.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-123ce6c502bff9d0.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-06870b92163db024.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-1effb405a319dacc.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-7589255974e45aba.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-4d833425ca8bff8b.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-3eada4a94d4275f4.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-3cfbf5662c5ce7e9.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-eafbed902bac58a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-b5d7a1337ffa209a.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-e62bbbd6b61adaf8.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-d482bcf05c779604.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-3defe3531234b706.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-7096379764d513bf.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-4239c751af300c04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-d482bcf05c779604.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-d5b28a58edc73240.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-f124151538779717.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/1129359-9620ea0cbce2fad9.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2018-02-08T00:58:41.114Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="浅入浅出深度学习理论实践">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/1129359-c6cc20032d7d0314.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://sladesha.github.io/2018/02/07/浅入浅出深度学习理论实践/"/>





  <title>浅入浅出深度学习理论实践 | SladeSha's Algorithm World</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SladeSha's Algorithm World</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Keep Learning</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-me">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            ME
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://sladesha.github.io/2018/02/07/浅入浅出深度学习理论实践/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="沙韬伟 sladesha">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/image/1.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SladeSha's Algorithm World">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">浅入浅出深度学习理论实践</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-07T16:29:34+08:00">
                2018-02-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6,947 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  25 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="http://upload-images.jianshu.io/upload_images/1129359-c6cc20032d7d0314.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br><a id="more"></a></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前在知乎上看到这么一个问题：<a href="https://www.zhihu.com/question/266368852/answer/307130218" target="_blank" rel="noopener">在实际业务里，在工作中有什么用得到深度学习的例子么？用到 GPU 了么？</a>，回头看了一下自己写了这么多东西一直围绕着traditional machine learning，所以就有了一个整理出深度学习在我熟悉的风控、推荐、CRM等等这些领域的用法的想法。</p>
<p>我想在这边篇文章浅入浅出的谈谈这几个方面，当然深度学习你所要了解必然不仅仅如此，后面如果有机会我会一篇篇的完善：</p>
<ul>
<li>CNN/RNN理解</li>
<li>Attention理解</li>
<li>深度学习（CNN和RNN）传统领域的简单应用</li>
<li>关于深度学习的一些想法</li>
</ul>
<p>大概会将全文分为以上几块，大家可以跳读，因为本文理论上应该会冗长无比，肯定也包括数据块+代码块+解析块，很多有基础的同学没有必要从头在了解一遍。好了，让我们正式开始。</p>
<h1 id="CNN-RNN理解"><a href="#CNN-RNN理解" class="headerlink" title="CNN/RNN理解"></a>CNN/RNN理解</h1><h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><p>CNN，卷积神经网络，让我们先从一个简单的网络结构来梳理一下：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-772dffb29dc4d9c0.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h3 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h3><p>假如，我们有car,plane,desk,flower等等<strong>一共十类的图片</strong>，需要让电脑识别图片是哪种的话，自然需要把图片变成电脑理解的了的一种方式，比如：RxGxB（图片的高度、宽度和深度）也就是上面<strong>输入层</strong>32x32x3，至于什么是RGB，请自行阅读<a href="https://baike.baidu.com/item/RGB/342517?fr=aladdin" target="_blank" rel="noopener">RGB百度百科</a>。</p>
<h3 id="卷积层一-卷积层二"><a href="#卷积层一-卷积层二" class="headerlink" title="卷积层一/卷积层二"></a>卷积层一/卷积层二</h3><p><img src="http://upload-images.jianshu.io/upload_images/1129359-47d1b5a6fb64a4f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>这张图片我觉得形象的不能再形象了，让我们结合代码和图形来理解这个卷积到底是什么意思。tensorflow中卷积的集成代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">filter_weights = tf.Variable(tf.truncated_normal([window_size, embed_dim, <span class="number">1</span>, filter_num], stddev=<span class="number">0.1</span>),name=<span class="string">"filter_weights"</span>)</span><br><span class="line"></span><br><span class="line">conv_layer = tf.nn.conv2d(item_embed_layer_expand, filter_weights, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"VALID"</span>,name=<span class="string">"conv_layer"</span>)</span><br></pre></td></tr></table></figure>
<p>filter_weights的shape是window_sizexembed_dimx1xfilter_num，window_sizexembed_dimgx1就是类似于gif图中的黄色区域的大小，这边就可以看作window_size=embed_dim=3，filter_weights第三维的1是指HRG中的第三维度：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-071901b190573269.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>filter_weights第三维如果是2的话：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-d2bd2d98ce6fd07d.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>想到于多了一维的并行处理，接下来看filter_weights的filter_num，最上方的gif的动图解释了卷积层的计算形式：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-0ed7c1c4734f9206.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>黑色字体的1/0矩阵是原来图像的像素值，红色的1/0是上面设置filter_weights值，他们的分别计算后的累计值即为一次扫描计算结果，比如黄色区域即为1x1+1x0+0x1+1x0+1x1+1x0+0x1+1x0+1x1.将所有的像素值所在的位置都进行一次扫描后就可以得到：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-a79b2232f850395b.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>当然，除了随机生产filter_weights，图像操作中，指定不同的filter_weights会起到不同的作用：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-1ce76cadc5718922.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>但是这里面存在两个问题：</p>
<ul>
<li>边界扫描</li>
<li>扫描速度</li>
</ul>
<h4 id="边界扫描（padding-”VALID”）"><a href="#边界扫描（padding-”VALID”）" class="headerlink" title="边界扫描（padding=”VALID”）"></a>边界扫描（padding=”VALID”）</h4><p><img src="http://upload-images.jianshu.io/upload_images/1129359-a1a5d8e2b907771f.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br>VALID模式如上图所示，对原始图像进行卷积，卷积后的矩阵只有3×3阶，比原来的图片要小了。</p>
<p>SAME模式要求卷积后的feature map与输入的矩阵大小相同，因此需要对输入矩阵的外层包裹n层0，然后再按照VALID的卷积方法进行卷积。</p>
<p>n的求法如下式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SAME：</span><br><span class="line">edge_row = (kernel_row - 1) / 2</span><br><span class="line">edge_cols = (kernel_cols - 1) / 2</span><br><span class="line">VALID：edge_row = edge_cols = 0</span><br></pre></td></tr></table></figure>
<p>其中，edge_row是包裹0的行数，edge_cols是包裹0的列数 , kernel_row就卷积核的行数。</p>
<h4 id="扫描速度（tf-nn-conv2d中的-1-1-1-1-）"><a href="#扫描速度（tf-nn-conv2d中的-1-1-1-1-）" class="headerlink" title="扫描速度（tf.nn.conv2d中的[1,1,1,1]）"></a>扫描速度（tf.nn.conv2d中的[1,1,1,1]）</h4><p>这个概率也是最好理解的了，就是图中的黄色方框位移的速度：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-56235bdd16fba64e.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>回到最上面filter_num，filter_num的值就是重复上述流程的次数，随着次数的增加，会增加后面pooling层的基础数据层数：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-a186f2410acb046d.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br>每次黄色箭头后的pool层的层数就是filter_num。</p>
<p>到此为止，卷积层就简单的梳理完了，主要是要清楚几个概念：filter_weights的作用，filter_num的定义，padding的差异，还有扫描的速度。这些主要是围绕着下面我要实际应用的场景梳理的卷积神经网络的知识点，如果要深刻透彻的了解还需要更多更深入的解读。</p>
<h3 id="池化层一-池化层二"><a href="#池化层一-池化层二" class="headerlink" title="池化层一/池化层二"></a>池化层一/池化层二</h3><p>先从数学角度来看，它的操作步骤：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-1277229fc560f408.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>这张图看起来，和卷积层中的image –&gt; Convolved feature非常类似，也是确定一个shape之后，对shape内的数据进行操作，但是差异就在：<strong>卷积层中是采取对image里面的像素点逐点计算后汇总，相当于加权了每个像素点的作用；而池化层通常采用最大/最小/均值/求和等方式汇总Convolved feature</strong>。</p>
<p>罗列出来就是：</p>
<ul>
<li>对象不同，一个是image，一个是Convolved feature</li>
<li>计算方式不同，一个matrix点对点乘积后求和，一个是直接求和（或者其他聚合操作）</li>
</ul>
<p>池化层数学的操作比较简单，在实际工程中的理解比较让人困惑，其实，意义主要在三点：</p>
<ul>
<li>其中一个显而易见，就是减少参数。通过对 Feature Map（通过的手段是聚合计算） 降维，有效减少后续层需要的参数</li>
<li>一个是 Translation Invariance。它表示对于 Input，当其中像素在邻域发生微小位移时，Pooling Layer 的输出是不变的。这就使网络的鲁棒性增强了，有一定抗扰动的作用</li>
<li>另一个是以区块的角度代替逐个点进行计算，降低每个点对最后结果的影响，避免了过拟合的现象</li>
</ul>
<h3 id="全连接层-输出层"><a href="#全连接层-输出层" class="headerlink" title="全连接层/输出层"></a>全连接层/输出层</h3><p>这个就比较简单了，全连接层（FC）构造如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.layers.dense(brand_embed_layer, embed_dim, name=<span class="string">"brand_fc_layer"</span>, activation=tf.nn.relu)</span><br></pre></td></tr></table></figure>
<p>简单的来说，通过activation增加了特征的非线性的拟合能力；如果不设置activation的话，就增加了特征的线性拟合能力。</p>
<p>但是，我们要知道，全连接层会有很多缺陷：</p>
<p>在一定程度上，可以通过增加全连接的层数提高train data的准确率，但是如果过分的增加，会造成过拟合，所以如果是自己写的网络，一定程度上，如何控制还好全连接层的数量决定了valid data了准确率的波动。其实，完全可以通过pool层代替全连接层，17年年初很多论文指出：GAP（Global Average Pooling）的方法可以代替FC（全连接）。思想就是：用 feature map 直接表示属于某个类的 confidence map，比如有10个类，就在最后输出10个 feature map，每个feature map中的值加起来求平均值，然后把得到的这些平均值直接作为属于某个类别的 confidence value，再输入softmax中分类， 更重要的是实验效果并不比用 FC 差，所以全连接层的分类器的作用就可以被pool层合理代替掉。</p>
<p>而且，全连接层参数冗余（仅全连接层参数就可占整个网络参数60%-80%），计算量会集中在这些参数的计算上，而且随着你的层数的增加，你的计算成本越来越大，如果是非GPU的机器在计算的过程中会非常非常吃亏。</p>
<p>之所以，现在的很多很多流行网络还是以FC参与计算的原因：</p>
<ul>
<li>简单，很方便了解。而且当前的各个计算框架tensorflow，caffe等等对FC的封装即成也是非常的完善</li>
<li>借鉴非常容易。举个例子，如果已经有了一个通过输出层产出10类的模型，我现在要做一个5类的模型的话，我只需要在最后一次FC层后面增加一个embed_dim=5的FC层即可。</li>
</ul>
<p>上面就简单了梳理了CNN里面的简单的网络结构，是不是真的就是这么简单呢？让我们看看上面叫做相对成熟的网络：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-33c3f5aa3d6445a7.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>图像中几年前的技术，Alexnet，SSD，Yolo，还有去年的RCNN，fast-RCNN等等，网络结构都远远比我们想象中的要复杂，在对数据操作的行为中，无非也是上面这些操作的一些组合。</p>
<p>再次强调，本文重点不在介绍CNN，而是利用CNN作为传统机器学习做协助，所以，如果想要深入了解CNN的同学建议从头开始学习，不建议阅读我这种跳讲的内容作为入门。</p>
<h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><p>相比CNN而言，RNN要简单而又有趣一些：</p>
<p>几乎所有的讲RNN的技术文章都会有下面这张图，无法免俗，因为确实囊括了RNN的核心：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-246995854fe4a3f1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>不得不说，nlp是RNN非常优秀的应用场景，我们从nlp的角度去切入，观察RNN在其中所起的作用也是非常好的一个方式：<br>假设有一句话：“今天天气真的不是很好，让我们去<em>__</em>吧。”</p>
<p>如果用朴素贝叶斯来解决这个填空问题，它的解决思路是：</p>
<ul>
<li>先分词，今天，天气，真的，不是很好，让，我们，去，吧</li>
<li>去除语气词等，剩余天气，不是很好，我们，去</li>
<li>再根据贝叶斯公式得到概率最大的值</li>
</ul>
<p>如果用N-Grams来解决这个填空问题，它的解决思路是：</p>
<ul>
<li>先分词，今天，天气，真的，不是很好，让，我们，去，吧</li>
<li>去除语气词等，剩余天气，不是很好，我们，去</li>
<li>根据前缺失词的前N个词的条件概率来计算出具有最大概率的缺失值</li>
</ul>
<p>朴素贝叶斯的方法只考虑每个词出现的结果没有考虑先后顺序，可能导致由意外的非真实排序决定缺失值的问题；N-Grams的方法虽然考虑了每个词出现的可能的同时，也考虑缺失值前N个词的内容，但是由于计算能力的约束，并不能够完整的保留全部的前置语句的信息。</p>
<p>而RNN的出现，利用state层来存储前面t-1刻的信息，并循环传递在每次输出计算中，解决ngram做不到的完整信息保存的问题，如下图：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-0fb4f9504f5a996a.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>很明显，在对Yt+2的结果预测的时候，考虑到了前面所有前置的信息。<img src="http://upload-images.jianshu.io/upload_images/1129359-123ce6c502bff9d0.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>这张图很好的解释了RNN的传递逻辑，将所有前期的信息以state的形式进行传递，在第t次的输出结果计算的过程中，不仅仅考虑第t次的输入值，同时考虑t-1次的state，也就是前t-1层的信息的流动汇总结果。我们知道，最简单最基础的RNN里面，可以通过tanh层来合并t-1时刻的state和t时刻的xt信息的。虽然理论上来说，无论信息是各多远，RNN都能够记得，但是！但是！实际上，我们发现，RNN随着tanh的重复操作，是无法稍远的信息就无法合理的被记忆，幸运的是后面优化出来的LSTM和GRU就能一定程度上缓解这些的问题。</p>
<p>下面让我们以GRU为例子，具体看看RNN是怎么进行一次循环神经网络的计算的：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-06870b92163db024.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>这边大家需要注意，与LSTM不同，GRU将LSTM中的输入门和遗忘门合并成了更新门。而且没有建立中间过渡键memory cell，而是直接通过更新门和重置门来更新state。这样做的好处就是大大的降低了计算的成本，加快了整个RNN训练的速度。同时通过各种Gate将重要特征保留，保证其在long-term传播的时候也不会被丢失，也有利于BP的时候不容易造成梯度消失。</p>
<p>在RNN的官方论文中，我们看到了实测的效果如下：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-1effb405a319dacc.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>很明显的可以看到，1.虽然GRU减少了一个门的存在，但是效果与LSTM相当，但是几乎每次测试的test效果都要优秀于传统方法。2.GRU是真的肉眼可见的比LSTM快，证实了我们上述说的内容。也是因为这些原因，在后面为实际应用的过程中，我也是选择了GRU来代替了LSTM做向量化及state层提取等等操作。</p>
<p>问题来了，虽然我知道LSTM和GRU在最后实测的效果上是比直接用tanh的简单RNN效果要好的，但是我也无法解释和理解为什么这样的构造就能够有这样的提升，这就比较尴尬了。</p>
<p>另外要提的一点就是，在GRU实际计算的过程中，采取了学习参数拼接的方式，比如上面的Wz，Wr等是通过拼接的方式存储的，在需要的计算的时候再拆分开进行计算：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-7589255974e45aba.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>这也是让我在学习GRU过程中眼前一亮的点，非常值得玩味的地方。</p>
<h1 id="Attention理解"><a href="#Attention理解" class="headerlink" title="Attention理解"></a>Attention理解</h1><p>在篇幅如此冗长的情况下，我依然坚持要和大家讨论一下关于Attention的一些看法和观点，我觉得正是有attention的存在，才让我们能够想到如何更好的去扩展应用这些深度学习的方法。</p>
<p>我之前一直没有找到很好的通俗易懂的解释attention的文章，这边我尝试以业务的角度为大家分析一下，尽可能的抛开数学的角度让大家浅入浅出一下。</p>
<p>假设存在用户A，及他的各种行为A_actions，如果我不做任何操作简单的把他的各种行为A_actions当成变量进行模型训练可以得到模型AM。但是，如果我知道，他可能是一个2年前流失近期活跃的用户，我选择剔除他两年前的A_actions，而只考虑他近期的行为，这样的过程其实就是一个Attention的过程，因为我们要预测他近期可能买什么，所以我们应该把关注点集中在了他近期的部分信息而不是全部信息上。</p>
<p>而在深度学习运用的过程中，我们也应该考虑attention的问题，比如用户商品点击流为A–&gt;B–&gt;A–&gt;C–&gt;D，我们常规操作是什么样的？无非是：</p>
<ul>
<li>生成4xembed_dim的embedding层</li>
<li>将ABCD四个商品编号为0123</li>
<li>找到对应商品在embedding层中的向量表示</li>
<li>Encoder过程完成</li>
<li>通过RNN或者其他深度学习网络进行非线性Decoder输出对应的可能结果</li>
</ul>
<p>以上就是一个非常简单的Encoder-Decoder过程。</p>
<p>仔细想想其实就会发现很多不合理的地方，比如我在B商品停留了2mins，而其他商品均只停留了不到10s；再比如，我有购买C商品的历史，ABD商品均为第一次接触等等。其实，对于ABCD而言，简单的理解就是它们为不是等权的。而且我们发现，随着你的信息量的增加，也就是item点击流的长度增加，encoder的信息丢失就会变得非常严重，decoder的难度会大大的提升。</p>
<p>回过头来看上述的流程，如果变成：</p>
<ul>
<li>生成4xembed_dim的embedding层</li>
<li>将ABCD四个商品编号为0123</li>
<li>找到对应商品在embedding层中的向量表示</li>
<li>Xa,Xb,Xc,Xd = ∑(aiA,biB,ciC,diD)</li>
<li>通过RNN或者其他深度学习网络进行非线性Decoder输出对应的可能结果</li>
</ul>
<p>换句话说，就是在坑爹的Encoder到Decoder过程中，增加了缓冲计算Ci，通过构造Ci代替Encoder结果进行Decoder的过程，让深度学习的过程更加的合理。<br><img src="http://upload-images.jianshu.io/upload_images/1129359-4d833425ca8bff8b.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>数学的形式就是:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y1=f1(C1)</span><br><span class="line">y2=f1(C2,y1)</span><br><span class="line">y3=f1(C3,y1,y2)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>比如我在B商品停留了2mins，而其他商品均只停留了不到10s时，我们就可以构造缓冲C=g(0.1xf(A)+0.6xf(B)+0.1xf(C)+0.1xf(D))，这意味着A–&gt;B–&gt;A–&gt;C–&gt;D–&gt;?，对于？的判断，B起了比ACD都要重要的作用。</p>
<p>大名鼎鼎的RNN在attention的机制下就会变成：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-3eada4a94d4275f4.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>那么具体如何构造缓冲C呢，我们看下面这个流程：<br>首先，在RNN最初参数设置的时候，我们会确定init memory，不妨记为z0；hi为当前时刻输出的隐层输出向量，所以对每个商品ABCD都有一个z0与hi的相似度∂0i：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-3cfbf5662c5ce7e9.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br>在每次循环之前，相当于考虑了当前所有的输入（比如此刻的ABCD）与initmemory的匹配度，至于匹配度match在论文中的计算方式为：矩阵变换α=hTWz (Multiplicative attention，Luong et al., 2015) ，其实简化为余弦相似度也是可以的，只要能判断两者之间的相似程度都行。算出所有的∂0a,∂0b,∂0c,∂0d后归一化后的值即可作为ABCD对应的隐层ha，hb，hc，hd的权重：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-eafbed902bac58a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>c0即可作为rnn的输入，有c0和z0，我们非常容易可以算出z1，得到z1后，重复上述的过程可以得到c1…，如此循环，直到结束。<a href="https://arxiv.org/abs/1412.7449" target="_blank" rel="noopener">论文中的计算方式</a>如下：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-b5d7a1337ffa209a.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>和nlp中构造方式对比起来，还是有一定的差异，nlp的训练集往往是确定的。比如：“我爱学习”翻译为“i love studying”，我翻译为i，所以我确定一定要对“i”进行翻译的时候，需要提高对应i的权重。而我在商品点击流预测购买概率的时候，只能通过停留时长，历史是否购买过来建立约等的关系，但是这个约等的关系是不存在强成立的前提的。</p>
<p>attention的机制最初理解起来有点绕，但是如果能够搞懂并在我们做深度网络设计中应用起来，理论上收益还是非常之大的，建议大家把上述为贴的论文详读一边，真的是写的非常不错的一篇文章。</p>
<h1 id="深度学习传统领域的应用"><a href="#深度学习传统领域的应用" class="headerlink" title="深度学习传统领域的应用"></a>深度学习传统领域的应用</h1><p>我们先来回想一下，我们做传统有监督是怎么做的，如果记不得了，可以回顾这篇文章：<a href="http://shataowei.com/2018/01/20/提升有监督学习效果的实战解析/" target="_blank" rel="noopener">提升有监督学习效果的实战解析</a>，我认为有几点传统有监督学习不是很友好：</p>
<ul>
<li>特征工程</li>
<li>实效性</li>
<li>数据解析能力</li>
</ul>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>想必有过特征工程项目经验的同学可能是对数据预处理及特征筛选过程心有余悸：</p>
<ul>
<li>是不是用户信息，商品信息，用户历史信息，商品信息统计属性刻画，用户行为整合每一块写hive都要很久很久？跑数据的时间更久？</li>
<li>是不是数据好不容易跑出来了，各种垃圾信息，各种格式问题，pandas，numpy来回折腾到几百行的代码？</li>
<li>是不是好不容易数据处理完，一跑结果auc0.6？修改都不知道怎么修改？</li>
<li>是不是四处看别人整理的调参心得，比如这个家伙的<a href="http://shataowei.com/2017/12/30/Kaggle-TianChi分类问题相关纯算法理论剖析/" target="_blank" rel="noopener">Kaggle&amp;TianChi分类问题相关纯算法理论剖析</a>,然后发现优化后就提升了1个点？</li>
<li>是不是上线之后发现数据量一旦一大，你本地跑的脚本全部都报出：<code>MemoryError</code>?</li>
<li>是不是立项一周后产品经理过来问什么时候上线的时候，你连数据还没整理完？</li>
</ul>
<p>诸如这样坑爹的事情实在多的不能再多，相对而言，无论是是CNN还是RNN或者其他深度学习网络的input都是非常简单很清晰的，我这边给出一些简单的例子：</p>
<p>你在构造卷积神经网络的时候，只需拿出商品的基础属性，然后用不同性质的向量化方法embedding成不同的向量对象进行channel叠加就行了：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-e62bbbd6b61adaf8.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>你在构造循环神经网络的时候，只需拿出用户商品的点击流，然后构造一个流通的点对点的循环网络即可：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-d482bcf05c779604.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>卷积网络的原始数据只需要整理item与attribute对应关系，循环网络的原始数据只需要整理item与clickflow对应关系，相比复杂的传统方法的各种技巧，特征工程的提取整理的时间会大大减少，而且在线上数据处理过程中发生<code>Memory Error</code>的可能也无限变小。</p>
<h2 id="实效性"><a href="#实效性" class="headerlink" title="实效性"></a>实效性</h2><p>这个就比较好理解了，如果我们需要知道用户在app上每一刻的下单概率分布，如果用传统方法实现难度比较大，比如汇总前若干长时间内的信息再处理加工成模型需要的形式，再通过模型判断概率，可能就不是实时概率预估了。</p>
<p>而如果按照上述深度学习特征梳理方法，离线训练训练好用户的点击信息商品信息，再利用训练好的模型加用户在app上的实时行为，去预测用户在app上每一步操作对目标变量的影响,虽然我在离线训练的时间会付出的更多，但是我在线上预测会更加快捷。</p>
<p>具体效果我们以订单预估为例，深度学习预估方法下我们会很容易看到<strong>一个用户</strong>从开始一个session到结束一个session的过程中，购买欲望的分布：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-3defe3531234b706.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>在用户购买欲望特别高涨的时候，通过相应的push或者文案提醒，促进用户下单，提高成单率。</p>
<p>除此之外，我们还可以观察到每一刻全平台用户的购买欲望分布：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-7096379764d513bf.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="数据解析能力"><a href="#数据解析能力" class="headerlink" title="数据解析能力"></a>数据解析能力</h2><p>在围绕构造特征的时候，我们在对过去的数据整理的过程中，其实构造的最多的就是“过去N天”，“历史上”，“最后一次”，“第一次至今”，等等。其实，这些构造方法要么是汇总整合一段时间的信息，要么是单点的考虑某个时刻的信息量。但是，深度学习一定程度上会选择的汇总过去的信息的累积，根据实际对最终结果的影响，改变单次行为上的权重，避免单次行为对因变量的错误影响。比如RNN中的state，上面RNN中的文章我也介绍了，它的生成其实就是保留了前t-1次中的部分信息。</p>
<p>知乎上有这么一个问题<a href="https://www.zhihu.com/question/266479309" target="_blank" rel="noopener">RNN方法能够捕捉到 传统时间序列回归中的 trend ，seasonality么？</a>,其实我也很好奇，在引入深度学习的fc层到machine learing做stack的时候，确实绝大部分都能提高auc，但是是不是因为这些深度学习方法能捕捉到传统的数据里面的类似trend这些难以统计描述的性质？</p>
<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p>说了这么多，我觉得还是以具体的例子来剖析比较有说服力，因为深度学习的模型相对比传统的模型代码要长很多很多，我这边只截取我认为比较重要的地方解释一下，想要看demo的去看我的<a href="https://github.com/sladesha/deep_learning" target="_blank" rel="noopener">GitHub</a>吧。我给出的例子都是最简单的网络设计，如果实际要应用大家可以按照自己业务的需求增加网络的深度，改变网络的结构，这边只是给大家一个方向。<strong>此外，数据的处理也并没有因为深度学习模型的出现而变得不重要，Garbage In, Garbage Out!!!</strong></p>
<p>RNN方案的思路是来自于Domonkos Tikk和Alexandros Karatzoglou在《Session-based Recommendations with Recurrent Neural Networks》</p>
<p>它构造了embedding层来把原始的输入item映射为一个长度定义好的向量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">embedding = tf.get_variable(<span class="string">'embedding'</span>, [self.n_risks, self.rnn_size], initializer=initializer)</span><br></pre></td></tr></table></figure>
<p>通过把user浏览或者点击过的item进行index编号X，然后根据编号去embedding层去找对应的vector，后续只要用用户接触到了该item就重复以上的embedding过程就行了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inputs = tf.nn.embedding_lookup(embedding, self.X)</span><br></pre></td></tr></table></figure>
<p>再构造了简单的GRU层来学习每次用户的点击先后顺序之间的关系：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多层简单GRU层定义</span></span><br><span class="line">cell = rnn_cell.GRUCell(self.rnn_size, activation=self.hidden_act)</span><br><span class="line">drop_cell = rnn_cell.DropoutWrapper(cell, output_keep_prob=self.dropout_p_hidden)</span><br><span class="line">stacked_cell = rnn_cell.MultiRNNCell([drop_cell] * self.layers)</span><br></pre></td></tr></table></figure>
<p>它的网络结构一点也不复杂：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-4239c751af300c04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>首先，需要把数据集构造成中间的uid+item+time的格式：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-d482bcf05c779604.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>然后通过用户自身点击item的顺序，以时间靠前的item项预测时间靠后的item项，训练完成后记录每条数据对应的out和state。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-d5b28a58edc73240.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>但是我实测了多层GRU和单层GRU，因为我们需要进行stacking的过程，不建议做多层的GRU，层数越多每层的信息量越稀薄，我通过sum，mean处理后仍不如单层：<br><img src="http://upload-images.jianshu.io/upload_images/1129359-f124151538779717.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<hr>
<p>CNN的方案通常可以采取以下通用的网络形式：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/1129359-9620ea0cbce2fad9.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>所以可优化的点我均在网络结构中标注了，但是我一直没有找到CNN再传统学习中比较好的应用方式，如果拿最后一个FC层的向量stacking实测效果并不理想，相关代码我也放在了GitHub中了，大家可以作为一个尝试性的demo去看。</p>
<p>一样的item的向量化处理方式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cate_embed_matrix = tf.Variable(tf.random_uniform([cate_max, embed_dim], <span class="number">-1</span>, <span class="number">1</span>),name=<span class="string">"cate_embed_matrix"</span>)</span><br><span class="line">cate_embed_layer = tf.nn.embedding_lookup(cate_embed_matrix, cate, name=<span class="string">"cate_embed_layer"</span>)</span><br></pre></td></tr></table></figure>
<p>网络结构中主要是通过构造全连接层和卷积层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 全连接</span></span><br><span class="line">cate_fc_layer = tf.layers.dense(cate_embed_layer, embed_dim, name=<span class="string">"cate_fc_layer"</span>, activation=tf.nn.relu)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积层</span></span><br><span class="line">filter_weights = tf.Variable(tf.truncated_normal([window_size, embed_dim, <span class="number">1</span>, filter_num], stddev=<span class="number">0.1</span>),name=<span class="string">"filter_weights"</span>)</span><br><span class="line">filter_bias = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[filter_num]), name=<span class="string">"filter_bias"</span>)</span><br><span class="line">conv_layer = tf.nn.conv2d(item_embed_layer_expand, filter_weights, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">"VALID"</span>,name=<span class="string">"conv_layer"</span>)</span><br><span class="line">relu_layer = tf.nn.relu(tf.nn.bias_add(conv_layer, filter_bias), name=<span class="string">"relu_layer"</span>)</span><br><span class="line">maxpool_layer = tf.nn.max_pool(relu_layer, [<span class="number">1</span>, sentences_size - window_size + <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],padding=<span class="string">"VALID"</span>, name=<span class="string">"maxpool_layer"</span>)</span><br></pre></td></tr></table></figure>
<p>然后再把所有全连接完和卷积完的vector拼接：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一层全连接</span></span><br><span class="line">cate_fc_layer = tf.layers.dense(cate_embed_layer, embed_dim, name=<span class="string">"cate_fc_layer"</span>,activation=tf.nn.relu)</span><br><span class="line">brand_fc_layer = tf.layers.dense(brand_embed_layer, embed_dim, name=<span class="string">"brand_fc_layer"</span>,activation=tf.nn.relu)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二层全连接</span></span><br><span class="line">bc_combine_layer = tf.concat([cate_fc_layer, brand_fc_layer, dropout_layer], <span class="number">2</span>) bc_combine_layer = tf.contrib.layers.fully_connected(bc_combine_layer, <span class="number">200</span>, tf.tanh)</span><br></pre></td></tr></table></figure>
<p>最后通过全连接输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inference_layer = item_combine_layer_flat</span><br><span class="line">inference = tf.layers.dense(inference_layer, <span class="number">2</span>, kernel_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>),kernel_regularizer=tf.nn.l2_loss, name=<span class="string">"inference"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="关于深度学习一些想法"><a href="#关于深度学习一些想法" class="headerlink" title="关于深度学习一些想法"></a>关于深度学习一些想法</h1><p>这篇文章终于要结束了，漫漫长文。图像、语音、自然语言处理这三个领域，深度学习的性能就是比传统方法好得多，无可辩驳。但是传统领域，比如点击率预估，风控概率预估，金融风险预估等等，我不赞成非得和深度学习扯上关系，我们应该想想：</p>
<ul>
<li>我们有足够大量的数据支撑计算么？</li>
<li>我们的业务需求允许我们进行大量黑盒计算么？</li>
<li>带来的“提高”允许你所付出的成本么？</li>
<li>使用者真的知道自己在做什么么？</li>
</ul>
<p>最后，我以血和泪的教训知道自己写的网络对模型的效果提升是非常非常小的，建议大家先熟知现有的成熟的网络：</p>
<ul>
<li>谷歌的wide&amp;deep思想，<a href="https://github.com/sladesha/deep_learning/tree/master/Wide%20%26%20Deep" target="_blank" rel="noopener">论文及快速上手的demo</a>。</li>
<li>Youtube的推荐，<a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf" target="_blank" rel="noopener">论文地址</a>。</li>
<li>网易考虑的考拉，<a href="http://cfm.uestc.edu.cn/~zhangdongxiang/papers/ICDE16_industry_231.pdf" target="_blank" rel="noopener">论文地址</a>。</li>
</ul>
<p>参考文献</p>
<p>[1] <a href="http://www.cnblogs.com/rgvb178/p/6017991.html" target="_blank" rel="noopener">Foundation of Convolutional Neural Networks</a></p>
<p>[2] <a href="https://zhuanlan.zhihu.com/p/25518711" target="_blank" rel="noopener">YJango的循环神经网络</a></p>
<p>[3] <a href="http://cs224d.stanford.edu" target="_blank" rel="noopener">Deep Learning for Natural Language Processing</a></p>
<p>[4] <a href="http://blog.csdn.net/wuzqChom/article/details/75792501" target="_blank" rel="noopener">Attention机制</a></p>
<p>[5] <a href="https://arxiv.org/abs/1606.07792" target="_blank" rel="noopener">Wide &amp; Deep Learning for Recommender Systems</a></p>
<p>[6] <a href="https://research.google.com/pubs/archive/45530.pdf" target="_blank" rel="noopener">Deep Neural Networks for YouTube Recommendations</a></p>
<p>[7] <a href="http://cfm.uestc.edu.cn/~zhangdongxiang/papers/ICDE16_industry_231.pdf" target="_blank" rel="noopener">Personal Recommendation Using Deep Recurrent Neural Networks in NetEase</a></p>
<p>[8] <a href="https://www.researchgate.net/publication/284579100_Session-based_Recommendations_with_Recurrent_Neural_Networks" target="_blank" rel="noopener">Session-based Recommendations with Recurrent Neural Networks</a></p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>有你们的支持，我们一定会走的更远</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/image/wechatpay.jpg" alt="沙韬伟 sladesha 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/image/alipay.jpg" alt="沙韬伟 sladesha 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/理论解析/" rel="tag"># 理论解析</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/20/提升有监督学习效果的实战解析/" rel="next" title="提升有监督学习效果的实战解析">
                <i class="fa fa-chevron-left"></i> 提升有监督学习效果的实战解析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/02/22/18年的自我约束及目标期望/" rel="prev" title="18年的自我约束及目标期望">
                18年的自我约束及目标期望 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="SOHUCS"></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/image/1.png"
                alt="沙韬伟 sladesha" />
            
              <p class="site-author-name" itemprop="name">沙韬伟 sladesha</p>
              <p class="site-description motion-element" itemprop="description">前滴滴出行风控算法负责人，前hp-Lab客户行为算法研究员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">41</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/seven_xi/activities" target="_blank" title="知乎">
                    
                      <i class="fa fa-fw fa-globe"></i>知乎</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="http://www.jianshu.com" target="_blank" title="简书">
                    
                      <i class="fa fa-fw fa-globe"></i>简书</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://github.com/sladesha" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:stw386@sina.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://twitter.com/slade_sha" target="_blank" title="Twitter">
                    
                      <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN-RNN理解"><span class="nav-number">2.</span> <span class="nav-text">CNN/RNN理解</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN"><span class="nav-number">2.1.</span> <span class="nav-text">CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#输入层"><span class="nav-number">2.1.1.</span> <span class="nav-text">输入层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积层一-卷积层二"><span class="nav-number">2.1.2.</span> <span class="nav-text">卷积层一/卷积层二</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#边界扫描（padding-”VALID”）"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">边界扫描（padding=”VALID”）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#扫描速度（tf-nn-conv2d中的-1-1-1-1-）"><span class="nav-number">2.1.2.2.</span> <span class="nav-text">扫描速度（tf.nn.conv2d中的[1,1,1,1]）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#池化层一-池化层二"><span class="nav-number">2.1.3.</span> <span class="nav-text">池化层一/池化层二</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全连接层-输出层"><span class="nav-number">2.1.4.</span> <span class="nav-text">全连接层/输出层</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNN"><span class="nav-number">2.2.</span> <span class="nav-text">RNN</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Attention理解"><span class="nav-number">3.</span> <span class="nav-text">Attention理解</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度学习传统领域的应用"><span class="nav-number">4.</span> <span class="nav-text">深度学习传统领域的应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#特征工程"><span class="nav-number">4.1.</span> <span class="nav-text">特征工程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实效性"><span class="nav-number">4.2.</span> <span class="nav-text">实效性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据解析能力"><span class="nav-number">4.3.</span> <span class="nav-text">数据解析能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#案例"><span class="nav-number">4.4.</span> <span class="nav-text">案例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关于深度学习一些想法"><span class="nav-number">5.</span> <span class="nav-text">关于深度学习一些想法</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">沙韬伟 sladesha</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">100.7k</span>
  
</div>


<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
